{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2420c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d580b",
   "metadata": {},
   "source": [
    "#### Contingency matrix (sklearn.metrics.cluster.contingency_matrix) reports the intersection cardinality for every true/predicted cluster pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c68e9f",
   "metadata": {},
   "source": [
    "#### performance of a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51b14d7",
   "metadata": {},
   "source": [
    "--  Perfectly matching labelings have all non-zero entries on the diagonal regardless of actual label values:\n",
    "\n",
    "-- Labelings that assign all classes members to the same clusters are complete but may not always be pure, hence penalized, and have some off-diagonal non-zero entries:\n",
    "    \n",
    "-- If classes members are completely split across different clusters, the assignment is totally incomplete, hence the matrix has all zero diagonal entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in \n",
    "certain situations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106cf028",
   "metadata": {},
   "source": [
    "#### The pair confusion matrix computes a 2 by 2 similarity matrix between two clusterings by considering all pairs of samples and counting pairs that are assigned into the same or into different clusters under the true and predicted clusterings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef57651",
   "metadata": {},
   "source": [
    "-- we might be understand how well clustered classified by using pair confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a576b84",
   "metadata": {},
   "source": [
    "-- pair confusion matrix is always 2 by 2, but confusion matrix is depend on number of features..n by n -n is number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c257ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically \n",
    "used to evaluate the performance of language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c963fe",
   "metadata": {},
   "source": [
    "#### There are two types of evaluation metrics for clustering, Extrinsic Measures: These measures require ground truth labels, which may not be available in practice. Intrinsic Measures: These measures do not require ground truth labels  (applicable to all unsupervised learning results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974de861",
   "metadata": {},
   "source": [
    "-- mostly extrinsic measure for supervised ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200117e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an \n",
    "extrinsic measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d4fa10",
   "metadata": {},
   "source": [
    "#### There are two types of evaluation metrics for clustering, Extrinsic Measures: These measures require ground truth labels, which may not be available in practice. Intrinsic Measures: These measures do not require ground truth labels (applicable to all unsupervised learning results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9c6a6",
   "metadata": {},
   "source": [
    "-- mostly INtrinsic measure for un supervised ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify \n",
    "strengths and weaknesses of a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de0f57",
   "metadata": {},
   "source": [
    "#### A confusion matrix represents the prediction summary in matrix form. It shows how many prediction are correct and incorrect per class. It helps in understanding the classes that are being confused by model as other class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0de05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised \n",
    "learning algorithms, and how can they be interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106c678",
   "metadata": {},
   "source": [
    "### Silhouette Coefficient, higher the value better the clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and \n",
    "how can these limitations be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7a223",
   "metadata": {},
   "source": [
    "#### Classification accuracy is not the best choice for classification problems with unbalanced target variables. Precision and recall can be used in such tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
